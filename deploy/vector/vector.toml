# Vector Configuration for Purl
# Collects Docker container logs and sends to Purl API
# Version: 1.0.0

data_dir = "/var/lib/vector"

[api]
enabled = true
address = "0.0.0.0:8686"

# =============================================================================
# SOURCES
# =============================================================================

# Docker container logs (excludes Vector itself to prevent loops)
[sources.docker]
type = "docker_logs"
exclude_containers = ["vector", "purl-vector", "*-vector"]

# Journald system logs (optional - uncomment if needed)
# [sources.journald]
# type = "journald"
# current_boot_only = true
# exclude_units = ["vector.service"]

# File logs (optional - uncomment if needed)
# [sources.file_logs]
# type = "file"
# include = ["/var/log/*.log", "/var/log/**/*.log"]
# exclude = ["/var/log/vector*.log"]
# read_from = "end"

# =============================================================================
# TRANSFORMS
# =============================================================================

[transforms.parse]
type = "remap"
inputs = ["docker"]
source = '''
# Extract service name from container name (remove leading slash)
container = string!(.container_name)
.service = replace(container, r'^/', "")

# Get hostname from environment or use default
.host = get_env_var("HOSTNAME") ?? get_env_var("HOST") ?? "docker-host"

# Ensure message is string
msg = string(.message) ?? ""

# Try to parse JSON logs for structured data
parsed, err = parse_json(msg)
if err == null {
    # Extract message from parsed JSON
    msg = parsed.msg ?? parsed.message ?? msg
    .message = msg
}

# Extract trace/request IDs from parsed JSON or message
.trace_id = ""
.request_id = ""
.span_id = ""
.parent_span_id = ""

if err == null {
    # JSON log - extract trace fields (support multiple naming conventions)
    .trace_id = string(parsed.trace_id ?? parsed.traceId ?? parsed.traceid ?? parsed."X-Trace-Id" ?? "") ?? ""
    .request_id = string(parsed.request_id ?? parsed.requestId ?? parsed.reqId ?? parsed.req_id ?? parsed."X-Request-Id" ?? "") ?? ""
    .span_id = string(parsed.span_id ?? parsed.spanId ?? parsed.spanid ?? "") ?? ""
    .parent_span_id = string(parsed.parent_span_id ?? parsed.parentSpanId ?? parsed.parent_id ?? parsed.parentId ?? "") ?? ""
}

# Fallback: extract trace IDs from message using regex
if .trace_id == "" {
    trace_match, trace_err = parse_regex(msg, r'(?i)(?:trace[-_]?id|traceid)[=:\s]+["\']?(?P<trace>[a-f0-9-]{16,36})["\']?')
    if trace_err == null {
        .trace_id = trace_match.trace ?? ""
    }
}
if .request_id == "" {
    req_match, req_err = parse_regex(msg, r'(?i)(?:request[-_]?id|requestid|req[-_]?id)[=:\s]+["\']?(?P<req>[a-f0-9-]{8,36})["\']?')
    if req_err == null {
        .request_id = req_match.req ?? ""
    }
}

# Detect log level with priority (most specific first)
level = "INFO"
if match(msg, r'(?i)\b(fatal|panic|critical)\b') {
    level = "FATAL"
} else if match(msg, r'(?i)\b(error|err|exception|failed)\b') {
    level = "ERROR"
} else if match(msg, r'(?i)\b(warn|warning)\b') {
    level = "WARN"
} else if match(msg, r'(?i)\b(debug|trace)\b') {
    level = "DEBUG"
} else if match(msg, r'(?i)\b(info)\b') {
    level = "INFO"
}

# If JSON had level, use it
if err == null {
    parsed_level = upcase(string(parsed.level ?? parsed.severity ?? "") ?? "")
    if parsed_level != "" {
        level = parsed_level
    }
}

.level = level
.raw = msg

# Store metadata as JSON
.meta = encode_json({
    "container_id": string(.container_id) ?? "",
    "image": string(.image) ?? "",
    "source": "docker",
    "stream": string(.stream) ?? "stdout"
})

# Clean up original fields
del(.container_id)
del(.container_name)
del(.image)
del(.stream)
del(.source_type)
del(.label)
'''

# =============================================================================
# SINKS
# =============================================================================

[sinks.purl]
type = "http"
inputs = ["parse"]
uri = "${PURL_URL}/api/logs"
method = "post"
compression = "none"

[sinks.purl.encoding]
codec = "json"

[sinks.purl.batch]
max_bytes = 1048576
max_events = 100
timeout_secs = 5

[sinks.purl.buffer]
type = "memory"
max_events = 5000
when_full = "block"

[sinks.purl.request]
concurrency = 10
timeout_secs = 30
rate_limit_duration_secs = 1
rate_limit_num = 100
retry_initial_backoff_secs = 1
retry_max_duration_secs = 10
headers.Content-Type = "application/json"
headers.X-API-Key = "${PURL_API_KEY}"

# Healthcheck for sink
[sinks.purl.healthcheck]
enabled = true

# =============================================================================
# METRICS
# =============================================================================

[sources.internal_metrics]
type = "internal_metrics"
scrape_interval_secs = 15

[sinks.prometheus]
type = "prometheus_exporter"
inputs = ["internal_metrics"]
address = "0.0.0.0:9598"
default_namespace = "vector"
