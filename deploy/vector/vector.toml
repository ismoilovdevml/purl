# Vector Configuration for Purl

data_dir = "/var/lib/vector"

[api]
enabled = true
address = "0.0.0.0:8686"

# =============================================================================
# SOURCES
# =============================================================================

# Docker container logs (excludes Vector itself to prevent loops)
[sources.docker]
type = "docker_logs"
exclude_containers = ["vector", "purl-vector", "*-vector"]

# =============================================================================
# TRANSFORMS
# =============================================================================

# Filter out noise (ClickHouse stack traces, Vector internal logs)
[transforms.filter_noise]
type = "filter"
inputs = ["docker"]
condition = '''
container = string!(.container_name)
msg = string(.message) ?? ""

# Skip empty messages
if msg == "" { return false }

# Skip Vector internal logs (prevent recursive logging)
if starts_with(msg, "vector::") { return false }
if contains(msg, "vector::internal_events") { return false }
if contains(msg, "Internal log [") { return false }

# Skip all ClickHouse internal noise
if contains(container, "clickhouse") {
    # Skip stack trace lines (number. something @ 0x...)
    if match(msg, r'^\d+\.\s') { return false }
    # Skip version-only lines
    if contains(msg, "(version ") { return false }
    # Skip connection/buffer errors
    if contains(msg, "Connection reset by peer") { return false }
    if contains(msg, "Write buffer has been canceled") { return false }
    if contains(msg, "WriteBufferFromHTTPServerResponse") { return false }
    if contains(msg, "StaticRequestHandler") { return false }
    if contains(msg, "DB::Exception") { return false }
    if contains(msg, "DB::NetException") { return false }
}

true
'''

[transforms.parse]
type = "remap"
inputs = ["filter_noise"]
source = '''
# Extract service name from container name (remove leading slash)
container = string!(.container_name)
.service = replace(container, r'^/', "")

# Get hostname from environment or use container hostname
.host = get_env_var("VECTOR_HOSTNAME") ?? get_hostname() ?? "unknown"

# Ensure message is string
msg = string!(.message)

# Try to parse JSON logs for structured data
parsed, err = parse_json(msg)
if err == null {
    # Extract message from parsed JSON
    msg_val, msg_err = get(parsed, ["msg"])
    if msg_err != null {
        msg_val, msg_err = get(parsed, ["message"])
    }
    if msg_err == null && msg_val != null {
        msg = to_string!(msg_val)
    }
    .message = msg
}

# Initialize trace fields
.trace_id = ""
.request_id = ""
.span_id = ""
.parent_span_id = ""

# Extract trace fields from JSON if available
if err == null {
    trace_val, t_err = get(parsed, ["trace_id"])
    if t_err == null && trace_val != null { .trace_id = to_string!(trace_val) }

    req_val, r_err = get(parsed, ["request_id"])
    if r_err == null && req_val != null { .request_id = to_string!(req_val) }
}

# Detect log level with priority (most specific first)
level = "INFO"
if match(msg, r'(?i)\b(fatal|panic|critical)\b') {
    level = "FATAL"
} else if match(msg, r'(?i)\b(error|err|exception|failed)\b') {
    level = "ERROR"
} else if match(msg, r'(?i)\b(warn|warning)\b') {
    level = "WARN"
} else if match(msg, r'(?i)\b(debug|trace)\b') {
    level = "DEBUG"
} else if match(msg, r'(?i)\b(info)\b') {
    level = "INFO"
}

# If JSON had level, use it
if err == null {
    level_val, lv_err = get(parsed, ["level"])
    if lv_err != null {
        level_val, lv_err = get(parsed, ["severity"])
    }
    if lv_err == null && level_val != null {
        parsed_level = upcase(to_string!(level_val))
        if parsed_level != "" {
            level = parsed_level
        }
    }
}

.level = level
.raw = msg

# Store metadata as JSON
container_id_str = to_string(.container_id) ?? ""
image_str = to_string(.image) ?? ""
stream_str = to_string(.stream) ?? "stdout"
.meta = encode_json({
    "container_id": container_id_str,
    "image": image_str,
    "source": "docker",
    "stream": stream_str
})

# Clean up original fields
del(.container_id)
del(.container_name)
del(.image)
del(.stream)
del(.source_type)
del(.label)
'''

# =============================================================================
# SINKS
# =============================================================================

[sinks.purl]
type = "http"
inputs = ["parse"]
uri = "${PURL_URL}/api/logs"
method = "post"
compression = "none"

[sinks.purl.encoding]
codec = "json"

[sinks.purl.batch]
max_bytes = 1048576
max_events = 100
timeout_secs = 5

[sinks.purl.buffer]
type = "memory"
max_events = 5000
when_full = "block"

[sinks.purl.request]
concurrency = 10
timeout_secs = 30
rate_limit_duration_secs = 1
rate_limit_num = 100
retry_initial_backoff_secs = 1
retry_max_duration_secs = 10
headers.Content-Type = "application/json"
headers.X-API-Key = "${PURL_API_KEY}"

# Healthcheck for sink
[sinks.purl.healthcheck]
enabled = true

# =============================================================================
# METRICS
# =============================================================================

[sources.internal_metrics]
type = "internal_metrics"
scrape_interval_secs = 15

[sinks.prometheus]
type = "prometheus_exporter"
inputs = ["internal_metrics"]
address = "0.0.0.0:9598"
default_namespace = "vector"
